{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8728063",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cd7801",
   "metadata": {},
   "source": [
    "A Support Vector Machine (SVM) is a powerful and versatile Machine Learning model, capable of performing linear or nonlinear classification, regression, and even outlier detection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458b632b",
   "metadata": {},
   "source": [
    "C is one of the hyperparameter where if c value is less it has broader decision street and c is more less width. If model is overfitting then regularize it by reducing C."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adf9b01",
   "metadata": {},
   "source": [
    "## SVM CLASSIFIER"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5aeb9728",
   "metadata": {},
   "source": [
    "LINEAR SVM CLASSIFIER\n",
    "1)LinearSVC - Linear functionality Support Vector Classifier\n",
    "    Hyperparameter: C -> width of the boundary, loss=\"hinge\", dual_parameter=false\n",
    "2)SVC model : kernel=\"linear\", C=1\n",
    "3)SGD Classifier : loss=\"hinge\" alpha = 1/(m*C) #handle online classification & huge datasets (not fit in memory issue)\n",
    "\n",
    "NON LINEAR SVM CLASSIFIER\n",
    "\n",
    "KERNEL:POLY\n",
    "To  handle non-linear datasets add more features->polynomial features\n",
    "1) Create pipeline with polynomial degree, StandardScalar, and LinearSVC\n",
    "or\n",
    "2)Pipeline with StandardScalar and SVC(kernel=poly)\n",
    "    Hyperparameters: Degree, coef(Theta):1, C   #coef0: how much model is influenced by high-degree vs low-degree polynomials\n",
    "\n",
    "KERNEL:RBF\n",
    "    hyperparameter: Gamma overfitting reduce it and underfitting increase it. C value also affects. \n",
    "    Gamma more bell-shaped curve narrower and less Gamma bell-shape more wider"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e485d3",
   "metadata": {},
   "source": [
    "As a rule of thumb use Linear SVC (LinearSVC faster than SVC(kernel=\"linear\")) Training set large and plenty of features.\n",
    "Or else try GuassianRBF Kernel "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88b8843",
   "metadata": {},
   "source": [
    "The algorithm takes longer if you require a very high precision. This is controlled by the tolerance hyperparameter ε (called tol in Scikit-Learn). In most classification tasks, the default tolerance is fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f895383",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2a171cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris[\"data\"][:, (2, 3)] # petal length, petal width\n",
    "y = (iris[\"target\"] == 2).astype(np.float64) # Iris-Virginica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "094ec584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('linear_svc', LinearSVC(C=1, loss='hinge'))])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf = Pipeline([\n",
    "(\"scaler\", StandardScaler()),\n",
    "(\"linear_svc\", LinearSVC(C=1, loss=\"hinge\")),\n",
    "])\n",
    "svm_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca5aad15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf.predict([[5.5, 1.7]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dd608e",
   "metadata": {},
   "source": [
    "### Polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1f8389f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('poly_features', PolynomialFeatures(degree=3)),\n",
       "                ('scaler', StandardScaler()),\n",
       "                ('svm_clf', LinearSVC(C=10, loss='hinge'))])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "polynomial_svm_clf = Pipeline([\n",
    "(\"poly_features\", PolynomialFeatures(degree=3)),\n",
    "(\"scaler\", StandardScaler()),\n",
    "(\"svm_clf\", LinearSVC(C=10, loss=\"hinge\"))\n",
    "])\n",
    "polynomial_svm_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4602ffed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polynomial_svm_clf.predict([[5.5, 1.7]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf3d932",
   "metadata": {},
   "source": [
    "### Polynomial Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1bb2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "poly_kernel_svm_clf = Pipeline([\n",
    "(\"scaler\", StandardScaler()),\n",
    "(\"svm_clf\", SVC(kernel=\"poly\", degree=3, coef0=1, C=5))\n",
    "])\n",
    "poly_kernel_svm_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee487913",
   "metadata": {},
   "source": [
    "### RBF KERNEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe67970",
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf_kernel_svm_clf = Pipeline([\n",
    "(\"scaler\", StandardScaler()),\n",
    "(\"svm_clf\", SVC(kernel=\"rbf\", gamma=5, C=0.001))\n",
    "])\n",
    "rbf_kernel_svm_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9692c4fa",
   "metadata": {},
   "source": [
    "## SVM REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fef8f01",
   "metadata": {},
   "source": [
    "SVM also supports linear and nonlinear regression. The trick is to reverse the objective: instead of trying to fit the largest pos‐sible street between two classes while limiting margin violations, SVM Regression\n",
    "tries to fit as many instances as possible on the street while limiting margin violations\n",
    "(i.e., instances off the street)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209c3894",
   "metadata": {},
   "source": [
    "The width of the street is controlled by a hyperparameter \"ε\". Epsilon less value less width and more value more width."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2a0608",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVR\n",
    "svm_reg = LinearSVR(epsilon=1.5)\n",
    "svm_reg.fit(X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546cb12c",
   "metadata": {},
   "source": [
    "To tackle nonlinear regression tasks, you can use a kernelized SVM model. For example, Figure 5-11 shows SVM Regression on a random quadratic training set, using a 2nd-degree polynomial kernel. There is little regularization on the left plot (i.e., a large C value), and much more regularization on the right plot (i.e., a small C value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad624b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "svm_poly_reg = SVR(kernel=\"poly\", degree=2, C=100, epsilon=0.1)\n",
    "svm_poly_reg.fit(X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
